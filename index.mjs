import dotenv from "dotenv";
dotenv.config();

import axios from "axios";
import readline from "readline";
import { HuggingFaceInferenceEmbeddings } from "@langchain/community/embeddings/hf";
import { RecursiveCharacterTextSplitter } from "langchain/text_splitter";
import { MemoryVectorStore } from "langchain/vectorstores/memory";

// 1. Figma ë¬¸ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
async function fetchFigmaDocumentText() {
  const fileKey = process.env.FIGMA_FILE_KEY;
  const token = process.env.FIGMA_TOKEN;

  const response = await axios.get(
    `https://api.figma.com/v1/files/${fileKey}`,
    {
      headers: {
        "X-Figma-Token": token,
      },
    }
  );

  const traverse = (node, texts = []) => {
    if (node.name) texts.push(node.name);
    if (node.characters) texts.push(node.characters);
    if (node.children) {
      for (const child of node.children) {
        traverse(child, texts);
      }
    }
    return texts;
  };

  const document = response.data.document;
  const textContents = traverse(document).filter(Boolean).join("\n");
  return textContents;
}

// 2. í”¼ê·¸ë§ˆ ë¬¸ì„œ ì½ê¸°
const rawText = await fetchFigmaDocumentText();

// 3. ë¬¸ì„œ ìª¼ê°œê¸°
const splitter = new RecursiveCharacterTextSplitter({
  chunkSize: 500,
  chunkOverlap: 100,
});
const docs = await splitter.createDocuments([rawText]);

// 4. HuggingFace ì„ë² ë”©
const embeddings = new HuggingFaceInferenceEmbeddings({
  apiKey: process.env.HUGGINGFACE_API_KEY,
  model: "sentence-transformers/all-MiniLM-L6-v2",
});

// 5. ë©”ëª¨ë¦¬ ë²¡í„°ìŠ¤í† ì–´ êµ¬ì„±
const vectorStore = await MemoryVectorStore.fromDocuments(docs, embeddings);

// 6. OpenRouter ê¸°ë°˜ LLM ì •ì˜
const openRouterModel = {
  call: async (prompt) => {
    const res = await axios.post(
      "https://openrouter.ai/api/v1/chat/completions",
      {
        model: "mistralai/mistral-7b-instruct", // ë¬´ë£Œ ëª¨ë¸
        messages: [{ role: "user", content: prompt }],
      },
      {
        headers: {
          Authorization: `Bearer ${process.env.OPENROUTER_API_KEY}`,
          "Content-Type": "application/json",
        },
      }
    );
    return res.data.choices[0].message.content;
  },
};

// 7. CLI ì¸í„°í˜ì´ìŠ¤
const rl = readline.createInterface({
  input: process.stdin,
  output: process.stdout,
});

console.log("ğŸ“ í”¼ê·¸ë§ˆ ë¬¸ì„œ ê¸°ë°˜ Q&A ë´‡ì…ë‹ˆë‹¤. ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:");
let chatHistory = [];

rl.on("line", async (line) => {
  const question = line.trim();
  const relevantDocs = await vectorStore.similaritySearch(question, 4);
  const context = relevantDocs.map((doc) => doc.pageContent).join("\n");

  const prompt = `
ë‹¤ìŒì€ í”¼ê·¸ë§ˆ ë¬¸ì„œ ë‚´ìš©ì…ë‹ˆë‹¤:

${context}

ìœ„ ë¬¸ì„œë¥¼ ì°¸ê³ í•´ì„œ ë‹¤ìŒ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µí•´ì£¼ì„¸ìš”:

ì§ˆë¬¸: ${question}
`;

  const answer = await openRouterModel.call(prompt);
  console.log(`\nğŸ¤– ${answer}\n`);
  chatHistory.push([question, answer]);
});
